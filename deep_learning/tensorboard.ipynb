{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory where to save the logs\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each log will be saved in a different subdirectory.\n",
    "# function to produce the name of the subdirectories\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()  # e.g., './my_logs/run_2023_02_21-10_24_08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 10:27:39.282720: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 10:27:39.282876: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)  # connects the input with the first hidden layer\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)  # connects both hidden layers\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])  # connects the input with the second hidden layer into a new concatenated layer\n",
    "output = keras.layers.Dense(1)(concat)  # connects the concatenated layer to the output\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/Documents/GitHub/study/study_env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 10:27:52.866503: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-21 10:27:52.999571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 1.6323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 10:27:55.078630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 3s 6ms/step - loss: 1.6323 - val_loss: 1.0186\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.6798 - val_loss: 0.6885\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.6067 - val_loss: 0.6152\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5638 - val_loss: 0.6793\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5320 - val_loss: 0.6218\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5074 - val_loss: 0.5971\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4876 - val_loss: 0.5761\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4719 - val_loss: 0.6594\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4594 - val_loss: 0.6456\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4485 - val_loss: 0.7056\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4394 - val_loss: 0.5637\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4318 - val_loss: 0.5340\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4250 - val_loss: 0.5718\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4192 - val_loss: 0.5191\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4141 - val_loss: 0.4742\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4095 - val_loss: 0.4599\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4055 - val_loss: 0.4370\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4019 - val_loss: 0.5110\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3982 - val_loss: 0.4735\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3954 - val_loss: 0.4871\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3925 - val_loss: 0.4417\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3903 - val_loss: 0.4150\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3878 - val_loss: 0.4721\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3861 - val_loss: 0.4171\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3845 - val_loss: 0.4374\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3829 - val_loss: 0.3990\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3816 - val_loss: 0.3954\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3802 - val_loss: 0.4219\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3787 - val_loss: 0.4265\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3774 - val_loss: 0.4871\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir, )\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorboard server\n",
    "# tensorboard --logdir=./my_logs --port 6006\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        # histograms (more specifically tf.zeros_like) seems to be an issue with the version of tensorflow-macos\n",
    "        # data = (np.random.randn(100) + 2) * step / 100  # some random data\n",
    "        # tf.summary.histogram(\"my_hist\", tf.convert_to_tensor(data), buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3)  # random 32x32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [f\"The step is {step}\", f\"Its square is {step**2}\"]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "062160904e485aabf708570f4d0b2f744fd591aec4f725c6f1f092b17cc9122d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
